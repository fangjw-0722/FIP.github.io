<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FIP enables real-time, accurate motion capture using daily garments by fusing flex and inertial sensors.">
  <meta name="keywords" content="FIP, Motion Capture, Wearable Sensors, Flex Sensors, IMU">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FIP: Robust Motion Capture on Daily Garments</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
</head>
<body>



<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors</h1>
            <div class="is-size-5 publication-authors">
                <span class="author-block">
                <a href="https://keunhong.com">Ruonan Zheng*</a><sup>1</sup>,
                <a href="https://utkarshsinha.com">Jiawei Fang*</a><sup>2</sup>
                </span>
            </div>
            <div class="is-size-5 publication-authors">
                <span class="author-block">
                <a href="https://jonbarron.info">Yuan Yao</a><sup>2</sup>,
                <a href="http://sofienbouaziz.com">Xiaoxia Gao</a><sup>2</sup>,
                <a href="https://www.danbgoldman.com">Chengxu Zuo</a><sup>2</sup>,
                <a href="https://homes.cs.washington.edu/~seitz/">Shihui Guo</a><sup>1,2</sup>,
                <a href="http://www.ricardomartinbrualla.com">Yiyue Luo</a><sup>2</sup>
                </span>
            </div>
            <p class="is-size-7 has-text-centered">* Equal contribution</p>
            <div class="column has-text-centered">
                <div class="publication-links">
                <span class="link-block">
                    <a href="./static/docs/FIP_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                    </a>
                </span>
                </div>
            </div>
            </div>
        </div>
        </div>
    </div>
    </section>





<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            What if our clothes could accurately capture our body motion? We introduce Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments embedded with flex and inertial sensors.
            By integrating two flex sensors and four Inertial Measurement Units (IMUs), FIP compensates for inevitable sensor displacements in loose wearables using a Displacement Latent Diffusion Model and a Physics-informed Calibrator.
            Our approach significantly improves motion capture accuracy and outperforms state-of-the-art real-time posture estimation methods, especially in elbow joint tracking.
            FIP paves the way for applications in human-computer interaction, rehabilitation, and fitness analysis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Video</h2>
    <div class="publication-video has-text-centered">
      <iframe src="https://www.youtube.com/embed/YOUR_VIDEO_ID" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>
</section>

<!-- fabrication -->

<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Fabrication</h2>
          <div class="content has-text-justified">
            <p>
              The fabrication of FIP garments follows a structured process integrating sensors seamlessly into daily wear.
              The system incorporates two flex sensors and four IMUs into a loose-fitting jacket, ensuring both comfort and accuracy.
              Sensors are embedded using heat pressing, and electrical components are routed through flexible wiring channels.
            </p>
            <p>
              The fabrication process consists of three stages: sensor assembly, fabric cutting, and garment integration.
              First, the flex sensors and IMUs are soldered onto their respective connection boards, forming the sensor network.
              Next, the garment is designed with specialized fabric patterns, ensuring proper placement of sensors.
              Finally, sensors are heat-pressed onto the fabric, with wiring seamlessly integrated to maintain garment flexibility and comfort.
            </p>
            <p>
              Our design prioritizes wearability and durability, making FIP suitable for real-world applications such as motion tracking in Metaverse, rehabilitation, and fitness monitoring.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Algorithm</h2>
      <div class="content has-text-justified">
        <p>
          FIP's motion capture algorithm consists of three core modules:
        </p>
        <ul>
          <li><strong>Displacement Latent Diffusion Model:</strong> This module synthesizes sensor displacement in various conditions, addressing real-time displacement of IMUs through a generative AI-based approach.</li>
          <li><strong>Physics-informed Calibrator:</strong> A calibration mechanism that registers flex sensor data under different wearing conditions, compensating for primary displacement effects.</li>
          <li><strong>Pose Fusion Predictor:</strong> A multi-modal fusion network that integrates readings from both IMUs and flex sensors to estimate accurate body postures.</li>
        </ul>
        <p>
          These components work in synergy to enhance robustness, ensuring precise motion tracking even in loose-fitting garments.
        </p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Performance</h2>
      <div class="content has-text-justified">
        <p>
          Our FIP system achieves state-of-the-art motion capture performance by significantly reducing tracking errors. Key evaluation metrics include:
        </p>
        <ul>
          <li><strong>Angular Error:</strong> Reduced joint rotation error compared to existing real-time motion capture methods.</li>
          <li><strong>Elbow Tracking Accuracy:</strong> Improved tracking of elbow joints due to the fusion of flex and inertial sensors.</li>
          <li><strong>Positional Error:</strong> Lower deviation in joint positions, ensuring higher accuracy in full-body motion estimation.</li>
          <li><strong>Robustness:</strong> Effective compensation for sensor displacement, enabling stable tracking in loose-fitting garments.</li>
        </ul>
        <p>
          These results highlight FIP’s potential for applications in human-computer interaction, rehabilitation, and immersive virtual environments.
        </p>
      </div>
    </div>
  </section>
  


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>© 2025 FIP Research Team.</p>
    </div>
  </div>
</footer>

</body>
</html>
